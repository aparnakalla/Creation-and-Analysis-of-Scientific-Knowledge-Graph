{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import fileinput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of \"NumberInt\" data type from the orginial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(r\"C:\\Users\\User\\Downloads\\dblpv13.json\", \"r+\",encoding='utf-8')\n",
    "f2=open(r\"C:/Users/User/Downloads/capstone_1gb.json\", \"a+\",encoding='utf-8')\n",
    "while True:\n",
    "    line=f.readline()\n",
    "    if('NumberInt' in line):        \n",
    "        #print(len(line),line)\n",
    "        if(\"n_citation\" in line):\n",
    "            line1=line.removesuffix('), \\n')\n",
    "            line_new=line1[0:19:]+ \"\\\"\"+line1[29::]+\"\\\",\" '\\n'\n",
    "            f2.writelines(line_new)\n",
    "            \n",
    "        elif(\"year\" in line):\n",
    "            line1=line.removesuffix('), \\n')\n",
    "            line_new=line1[0:13:]+ \"\\\"\"+line1[23::]+\"\\\",\" '\\n'\n",
    "            f2.writelines(line_new)\n",
    "        elif(\"type\" in line):\n",
    "            if (',' in line ):\n",
    "                line1=line.removesuffix('), \\n')\n",
    "                line_new=line1[0:17:]+ \"\\\"\"+line1[28::]+\"\\\",\" '\\n'\n",
    "                f2.writelines(line_new)\n",
    "            else:\n",
    "                line1=line.removesuffix(')\\n')\n",
    "                line_new=line1[0:17:]+ \"\\\"\"+line1[28::]+\"\\\"\" '\\n'\n",
    "                f2.writelines(line_new)\n",
    "    else:\n",
    "        f2.writelines(line)\n",
    "    if not line:\n",
    "        break \n",
    "\n",
    "\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"C:\\Users\\User\\Downloads\\capstone_500mb_1.json\",encoding = \"utf-8\")\n",
    "data_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing papers with no abstract and citations less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=[] \n",
    "cl1=[]\n",
    "for i in range(len(data_list)):\n",
    "    for key in data_list[i]:\n",
    "        if key==\"abstract\":\n",
    "            if data_list[i][key]!=\"\":\n",
    "                #print(data_list[i])\n",
    "                cl1.append(data_list[i])\n",
    "    \n",
    "for i in range(len(cl1)):\n",
    "    for key in cl1[i]:\n",
    "        if key==\"n_citation\":\n",
    "            if int(cl1[i][key])>=5:\n",
    "                cl.append(cl1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting the papers to particular domains (domain_list) and Removing useless attributes of authors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd=[]\n",
    "domain_list=[\"pattern recognition\",\"feature recognition\",\"distributed computing\",\"handwritting recognition\",\"cloud computing\",\"artificial intelligence\",\"machine learning\",\"neural networks\",\"robotics\",\"data science\",\"data mining\"]\n",
    "remove_auth_attr = [\"org\",\"sid\",\"email\",\"orgid\",\"orgs\",\"gid\",\"oid\",\"_id\",\"orcid\",\"bio\"]\n",
    "for i in range (len(cl)):\n",
    "    for key in cl[i]:\n",
    "        if key==\"fos\" or key==\"keywords\":\n",
    "            a=(cl[i][key])\n",
    "            for word in range(len(a)):\n",
    "                a[word]=a[word].lower()\n",
    "            for domain in domain_list:\n",
    "                if domain in a:\n",
    "                    if (cl[i]) not in fd:       \n",
    "                        fd.append(cl[i]) \n",
    "        if key == \"authors\":\n",
    "            temp = cl[i][key]\n",
    "\n",
    "            for j in temp:\n",
    "                for attr in list(j.keys()):\n",
    "                    if attr in remove_auth_attr:\n",
    "                        j.pop(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18116/1575179203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mremove_venue_attr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "#removing unwanted attributes of venue \n",
    "remove_venue_attr=[\"_id\"]\n",
    "for i in range(len(cl)):\n",
    "    for key in cl[i]:\n",
    "        if(key==\"venue\"):\n",
    "            temp=cl[i][key]\n",
    "            for j in temp:\n",
    "                for attr in list(j.keys()):\n",
    "                    if attr in remove_venue_attr:\n",
    "                        j.pop(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the data type of authors to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(cl):\n",
    "    names = []\n",
    "    if \"authors\" in cl[i]:\n",
    "        for j in cl[i][\"authors\"]:\n",
    "            if \"name\" in list(j.keys()):\n",
    "                names.append(j[\"name\"])\n",
    "        cl[i][\"authors\"]=names\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unncessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(cl):\n",
    "    if \"title\" in cl[i]:\n",
    "        cl[i][\"title\"] = cl[i][\"title\"].replace(\"'\",\"`\")\n",
    "        cl[i][\"title\"] = cl[i][\"title\"].replace(\"]\",\"\")       \n",
    "        cl[i][\"title\"] = cl[i][\"title\"].replace(\":\",\"\")\n",
    "        cl[i][\"title\"] = cl[i][\"title\"].replace(\".\",\"\")\n",
    "        cl[i][\"title\"] = cl[i][\"title\"].replace(\"-\",\"\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unwanted attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useless_attr=['pdf' ,'page_end', 'lang', 'volume', 'isbn', 'page_start', 'issn', 'issue']\n",
    "\n",
    "for i in fd:\n",
    "    for j in i.copy():\n",
    "        if j in useless_attr:\n",
    "            del i[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Limiting the number of urls to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(fd)):  \n",
    "    for key in fd[i]:\n",
    "        if key==\"url\":                \n",
    "            fd[i][key]=fd[i][key][0:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the self references "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while (i<len(fd)):\n",
    "    if 'references' in fd[i]:\n",
    "        j=0\n",
    "        while(j<len(fd[i]['references'])):\n",
    "            if(fd[i]['_id']==fd[i]['references'][j]):\n",
    "                fd[i]['references'].pop(j)\n",
    "                \n",
    "            j+=1\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the preprocessed data as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "keys = [\"_id\",\"title\",\"authors\",\"year\",\"keywords\",\"fos\",\"n_citation\",\"doi\",\"url\",\"abstract\",\"references\",\"venue\"]\n",
    "\n",
    "\n",
    "a_file = open(r\"C:\\Users\\User\\Desktop\\output_500mb_venue.csv\", \"w\",encoding='utf-8')\n",
    "dict_writer = csv.DictWriter(a_file, keys,extrasaction='ignore')\n",
    "dict_writer.writeheader()\n",
    "dict_writer.writerows(fd)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
